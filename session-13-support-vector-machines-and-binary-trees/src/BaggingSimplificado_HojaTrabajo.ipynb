{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging simplificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_friedman1\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creación del ejemplo de regresión\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_friedman1.html\n",
    "n_points = 200 # points\n",
    "x, y = make_friedman1(n_samples=n_points, n_features=10,noise=1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separación de la muestra en entrenamiento y prueba\n",
    "tam_test = 0.2\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=tam_test, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función error cuadrático medio.\n",
    "def Fun_ECM(v1,v2):\n",
    "    suma, n = 0, len(v1)\n",
    "    for i in range(n):\n",
    "        suma = suma + (v1[1]-v2[1])**2\n",
    "    return (suma**0.5)/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión Árbol Binario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementación del árbol binario\n",
    "regTree = DecisionTreeRegressor(random_state=1)\n",
    "regTree.fit(x_train,y_train)\n",
    "yhatAB = regTree.predict(x_test)\n",
    "print(\"El error cuadrático medio es igual a \",Fun_ECM(yhatAB,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gráfica comparativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhatAB_aux = np.copy(y_train).tolist()\n",
    "y_aux = np.copy(y_train).tolist()\n",
    "yhatAB_aux.extend(yhatAB)\n",
    "y_aux.extend(y_test)\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "plt.plot(range(1,len(yhatAB_aux)+1),yhatAB_aux,color=\"black\",linewidth=1.5,label=\"Árbol binario\")\n",
    "plt.plot(range(1,len(y_aux)+1),y_aux,color=\"red\",ls=\"--\",linewidth=1.0,label=\"Serie verdadera\")\n",
    "plt.axvline(x=n_points-tam_test*n_points,color=\"green\",linewidth=3)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construcción de bagging\n",
    "n_estimators=10\n",
    "bag = np.empty((n_estimators), dtype=object) #Construcción de un array con entradas vacias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bootstraping (notar como el muestreo se realiza en las bases de entrenamiento)\n",
    "for i in range(n_estimators):\n",
    "    ids = np.random.choice(range(0,len(x_train)),size=int(len(x_train)),replace=True) #array en donde hay x_test valores escogidos aleatoriamente de range(0,len(x_test))\n",
    "    np.unique(ids) #del arreglo, unique regresa (de manera ordenada de menor a mayor) los valores de manera única\n",
    "    x_boot = x_train[np.unique(ids)] #del array x_train se seleecionan los renglones (vectores) indicados por los índice ids\n",
    "    y_boot = y_train[np.unique(ids)] #del array y_train se seleecionan los renglones (vectores) indicados por los índice ids\n",
    "    bag[i] = DecisionTreeRegressor(random_state=1)\n",
    "    bag[i].fit(x_boot,y_boot)\n",
    "#Predicción por bagging (dado cada ajuste en la muestra se pronóstica en el conjunto de prueba)\n",
    "yhatbag = np.zeros(len(y_test))\n",
    "for i in range(n_estimators):\n",
    "    yhatbag = yhatbag + bag[i].predict(x_test)\n",
    "yhatbag = yhatbag/n_estimators\n",
    "print(\"El error cuadrático medio es igual a \",Fun_ECM(yhatbag,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhatAB_aux = np.copy(y_train).tolist()\n",
    "y_aux = np.copy(y_train).tolist()\n",
    "yhatAB_aux.extend(yhatbag)\n",
    "y_aux.extend(y_test)\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "plt.plot(range(1,len(yhatAB_aux)+1),yhatAB_aux,color=\"black\",linewidth=1.5,label=\"Árbol binario\")\n",
    "plt.plot(range(1,len(y_aux)+1),y_aux,color=\"red\",ls=\"--\",linewidth=1.0,label=\"Serie verdadera\")\n",
    "plt.axvline(x=n_points-tam_test*n_points,color=\"green\",linewidth=3)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bosque aleatorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators=10,max_features=5,random_state=1)\n",
    "rf.fit(x_train,y_train)\n",
    "yhatBA = rf.predict(x_test)\n",
    "print(\"El error cuadrático medio es igual a \",Fun_ECM(yhatBA,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhatBA_aux = np.copy(y_train).tolist()\n",
    "y_aux = np.copy(y_train).tolist()\n",
    "yhatBA_aux.extend(yhatBA)\n",
    "y_aux.extend(y_test)\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "plt.plot(range(1,len(yhatBA_aux)+1),yhatBA_aux,color=\"black\",linewidth=1.5,label=\"Bosque aleatorio\")\n",
    "plt.plot(range(1,len(y_aux)+1),y_aux,color=\"red\",ls=\"--\",linewidth=1.0,label=\"Serie verdadera\")\n",
    "plt.axvline(x=n_points-tam_test*n_points,color=\"green\",linewidth=3)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo 1. Ajuste de una curva no lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejemplo parábola\n",
    "M = pd.read_csv(\"C:\\\\Users\\\\ricardo\\\\Desktop\\\\ArbolesBinarios\\\\EjemploCircunferencia.csv\",dtype='str',encoding = \"ISO-8859-1\")\n",
    "M[[\"Y\",\"X\"]] = M[[\"Y\",\"X\"]].astype(float)\n",
    "M.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Árbol binario\n",
    "x, y = np.asarray(M[\"X\"]), np.asarray(M[\"Y\"])\n",
    "x = x.reshape(-1,1)\n",
    "y = y.reshape(-1,1)\n",
    "regTree = DecisionTreeRegressor(random_state=1)\n",
    "regTree.fit(x,y)\n",
    "yhatAB3 = regTree.predict(x)\n",
    "print(\"El error cuadrático medio es igual a \",Fun_ECM(yhatAB3,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regresión lineal\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(x,y)\n",
    "yhatRL2 = lin_reg.predict(x)\n",
    "print(\"El error cuadrático medio es igual a \",Fun_ECM(yhatRL2,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "plt.plot(x,yhatAB3,color=\"orange\",linewidth=1.5,label=\"Árbol binario\")\n",
    "plt.plot(x,yhatRL2,color=\"blue\",linewidth=1.5,label=\"Regresión lineal\")\n",
    "plt.plot(x,y,color=\"red\",ls=\"--\",linewidth=1.0,label=\"Serie verdadera\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 1. De manera simimilar al ejercicio anterior, realizar un comparativo entre el ajuste que proporciona un árbol binario respecto a una regresión lineal con los datos del archivo \"EjemploParabola.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
