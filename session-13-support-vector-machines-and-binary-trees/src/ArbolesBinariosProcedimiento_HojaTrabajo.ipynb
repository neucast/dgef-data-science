{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árboles binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('display.max_rows',None)\n",
    "from sklearn.datasets import make_friedman1\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lectura de base de datos\n",
    "M = pd.read_csv(\"C:\\\\Users\\\\ricardo\\\\Desktop\\\\ArbolesBinarios\\\\EjemploArbolBinario_2D.csv\",dtype='str',encoding = \"ISO-8859-1\")\n",
    "M[[\"Y\",\"X1\",\"X2\"]] = M[[\"Y\",\"X1\",\"X2\"]].astype(float)\n",
    "M.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función error cuadrático medio.\n",
    "def Fun_ECM(v1,v2):\n",
    "    suma, n = 0, len(v1)\n",
    "    for i in range(n):\n",
    "        suma = suma + (v1[1]-v2[1])**2\n",
    "    return (suma**0.5)/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construcción del árbol binario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformación de los datos en un arreglo de numpy.\n",
    "X_train = np.asarray(M[[\"X1\",\"X2\"]].copy(deep=True).reset_index(drop=True))\n",
    "X_test = np.asarray(M[[\"X1\",\"X2\"]].copy(deep=True).reset_index(drop=True))\n",
    "y_train = np.asarray(M[[\"Y\"]].copy(deep=True).reset_index(drop=True))\n",
    "y_test = np.asarray(M[[\"Y\"]].copy(deep=True).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creación de la clase nodo\n",
    "class TNode:\n",
    "    def __init__(self, depth, X, y):\n",
    "        self.depth = depth\n",
    "        self.X = X #Matriz de variables explicativas\n",
    "        self.y = y #Matriz de variables de respuesta\n",
    "        #Inicialización de parámetros de split\n",
    "        self.j = None #Coordenada para realizar la partición\n",
    "        self.xi = None #Valor de partición dentro de la coordenada\n",
    "        #Inicialización de un hijo vacío\n",
    "        self.left = None #Posteriormente en la función Construct_Subtree se define aquí un árbol\n",
    "        self.right = None #Posteriormente en la función Construct_Subtree se define aquí un árbol\n",
    "        #Inicialización del predictor del nodo\n",
    "        self.g = None\n",
    "    def CalculateLoss(self):\n",
    "        if(len(self.y)==0):\n",
    "            return 0\n",
    "        else:\n",
    "            return np.sum(np.power(self.y - self.y.mean(),2))\n",
    "treeRoot = TNode(0, X_train,y_train)\n",
    "print(\"Profundida del árbol\",treeRoot.depth)\n",
    "print(\"Variables explicativas del árbol\",treeRoot.X)\n",
    "print(\"Variable de respuesta del árbol\",treeRoot.y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Observación sobe localización de valores en un Data Frame\n",
    "print(X_train[:,0]) #Se regresa la primer columna de la matriz\n",
    "print(X_train[:,1]) #Se regresa la segunda columna de la matriz\n",
    "ids_bis = X_train[:,0]<=6\n",
    "print(ids_bis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función de split\n",
    "def DataSplit(X,y,j,xi):\n",
    "    ids = X[:,j]<=xi #X[:,j] es un arreglo formado por las entradas j de cada vector del arreglo original\n",
    "    Xt = X[ids == True, :] #Elementos del arreglo original que cumplen idf\n",
    "    Xf = X[ids == False, :]\n",
    "    yt = y[ids == True]\n",
    "    yf = y[ids == False]\n",
    "    return Xt, yt, Xf, yf\n",
    "#Ejemplo\n",
    "Xt, yt, Xf, yf = DataSplit(X_train,y_train,1,15)\n",
    "print(Xt)\n",
    "print(yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejemplo de función shape.\n",
    "m, n = X_train.shape\n",
    "print(\"Número de renglones\",m)\n",
    "print(\"Número de columnas\",n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función split óptimo, sólo en el caso inicial\n",
    "def CalculateOptimalSplit(node):\n",
    "    X = node.X\n",
    "    y = node.y\n",
    "    best_var = 0 #Dimensión en la que se relizará la partición\n",
    "    best_xi = X[0,best_var] #Valor en cada coordenada para relizar la división de la región factible\n",
    "    best_split_val = node.CalculateLoss()\n",
    "    m, n = X.shape\n",
    "    for j in range(0,n):\n",
    "        for i in range(0,m):\n",
    "            xi = X[i,j]\n",
    "            Xt, yt, Xf, yf = DataSplit(X,y,j,xi)\n",
    "            tmpt = TNode(0, Xt, yt)\n",
    "            tmpf = TNode(0, Xf, yf)\n",
    "            loss_t = tmpt.CalculateLoss()\n",
    "            loss_f = tmpf.CalculateLoss()\n",
    "            curr_val = loss_t + loss_f\n",
    "            if (curr_val < best_split_val):\n",
    "                best_split_val = curr_val\n",
    "                best_var = j\n",
    "                best_xi = xi\n",
    "    return best_var, best_xi #Coordenada de partición, valor para la partición (notar que es un valor de la muestra)\n",
    "#Ejemplo\n",
    "best_var, best_xi = CalculateOptimalSplit(treeRoot)\n",
    "print(\"Coordenada óptima para hacer la primer partición de la región factible\",best_var)\n",
    "print(\"Valor óptimo de la coordenada para hacer la patición\",best_xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejemplo función recursiva\n",
    "def f_factorial(n):\n",
    "    if n == 0 or n == 1:\n",
    "        y = 1\n",
    "    else:\n",
    "        y = n*f_factorial(n-1)\n",
    "    return y\n",
    "#Ejemplo\n",
    "n = 5\n",
    "print(\"El factorial del número \",n,\" es igual a \",f_factorial(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construcción del subárbol\n",
    "def Construct_Subtree(node, max_depth):\n",
    "    if(node.depth == max_depth or len(node.y) == 1): #El valor 1 es arbitrario para detener el algoritmo e indicar un número mínimo de valores para promediar\n",
    "        node.g = node.y.mean() #Aquí va la función que regresa el valor del árbol binario\n",
    "    else:\n",
    "        j, xi = CalculateOptimalSplit(node)\n",
    "        node.j = j #Coordenda para realizar la partición\n",
    "        node.xi = xi #Valor de la coordenada para realizar la partición\n",
    "        Xt, yt, Xf, yf = DataSplit(node.X, node.y, j, xi)\n",
    "        if(len(yt)>0):\n",
    "            node.left = TNode(node.depth+1,Xt,yt) #Se agrega un nodo derecho al nodo anterior\n",
    "            Construct_Subtree(node.left, max_depth) #Función recursiva\n",
    "        if(len(yf)>0):\n",
    "            node.right = TNode(node.depth+1, Xf,yf) #Se agrega un nodo derecho al nodo izquierdo\n",
    "            Construct_Subtree(node.right, max_depth) #Función recursiva\n",
    "    return node\n",
    "#Ejemplo\n",
    "maxdepth = 2\n",
    "T = Construct_Subtree(treeRoot, maxdepth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejemplo de visualización del árbol binario construido\n",
    "print(\"************************Nivel 0************************\")\n",
    "print(\"Nivel actual\",T.depth)\n",
    "print(\"Coordenada para clasificar\",T.j)\n",
    "print(\"Valor de la coordenada para clasificar\",T.xi)\n",
    "print(\"************************Nivel 1 izquierdo************************\")\n",
    "N1I = T.left\n",
    "print(\"Nivel actual\",N1I.depth)\n",
    "print(\"Coordenada para clasificar\",N1I.j)\n",
    "print(\"Valor de la coordenada para clasificar\",N1I.xi)\n",
    "print(\"************************Nivel 1 derecho************************\")\n",
    "N1D = T.right\n",
    "print(\"Nivel actual\",N1D.depth)\n",
    "print(\"Coordenada para clasificar\",N1D.j)\n",
    "print(\"Valor de la coordenada para clasificar\",N1D.xi)\n",
    "print(\"************************Nivel 2 izquierdo - izquierdo************************\")\n",
    "N2II = N1I.left\n",
    "print(\"Nivel actual\",N2II.depth)\n",
    "print(\"Coordenada para clasificar\",N2II.j)\n",
    "print(\"Valor de la coordenada para clasificar\",N2II.xi)\n",
    "print(\"************************Nivel 2 izquierdo - derecho************************\")\n",
    "N2ID = N1I.right\n",
    "print(\"Nivel actual\",N2ID.depth)\n",
    "print(\"Coordenada para clasificar\",N2ID.j)\n",
    "print(\"Valor de la coordenada para clasificar\",N2ID.xi)\n",
    "print(\"************************Nivel 2 derecho - izquierdo************************\")\n",
    "N2DI = N1D.left\n",
    "print(\"Nivel actual\",N2DI.depth)\n",
    "print(\"Coordenada para clasificar\",N2DI.j)\n",
    "print(\"Valor de la coordenada para clasificar\",N2DI.xi)\n",
    "print(\"************************Nivel 2 derecho - derecho************************\")\n",
    "N2DD = N1D.right\n",
    "print(\"Nivel actual\",N2DD.depth)\n",
    "print(\"Coordenada para clasificar\",N2DD.j)\n",
    "print(\"Valor de la coordenada para clasificar\",N2DD.xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict(X,node):\n",
    "    if(node.right == None and node.left != None):\n",
    "        return Predict(X,node.left)\n",
    "    if(node.right != None and node.left == None):\n",
    "        return Predict(X,node.right)\n",
    "    if(node.right == None and node.left == None):\n",
    "        return node.g\n",
    "    else:\n",
    "        if(X[node.j] <= node.xi): #Notar que se da como parámetro un renglon de características (no la matriz completa)\n",
    "            return Predict(X,node.left)\n",
    "        else :\n",
    "            return Predict(X,node.right)\n",
    "#Ejemplo\n",
    "y_hat = np.zeros(len(X_test))\n",
    "for i in range(len(X_test)):\n",
    "    y_hat[i] = Predict(X_test[i],treeRoot)\n",
    "ECM1 = Fun_ECM(y_hat,y_test)\n",
    "print(\"Error cuadrático medio = \", ECM1)\n",
    "#Definición de Data Frame para el comparativo de los resultados\n",
    "MComp1 = pd.DataFrame(index=range(len(y_hat)),columns=[\"Datos verdaderos\",\"Datos aproximados\"])\n",
    "MComp1[\"Datos verdaderos\"] = y_test\n",
    "MComp1[\"Datos aproximados\"] = y_hat\n",
    "MComp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejemplo de una predicción particular\n",
    "C_1 = Predict([1,3],treeRoot)\n",
    "C_2 = Predict([7,4],treeRoot)\n",
    "C_3 = Predict([2,8],treeRoot)\n",
    "C_4 = Predict([9,10],treeRoot)\n",
    "print(\"Pronóstico en el primer cuadrante \",C_1)\n",
    "print(\"Pronóstico en el segundo cuadrante \",C_2)\n",
    "print(\"Pronóstico en el tercer cuadrante \",C_3)\n",
    "print(\"Pronóstico en el cuarto cuadrante \",C_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cálculo mediante funciones definidas en Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparativo con el método de sklearn\n",
    "#Fuente: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "regTree = DecisionTreeRegressor(max_depth = 2)\n",
    "regTree.fit(X_train,y_train)\n",
    "y_hat2 = regTree.predict(X_test)\n",
    "ECM2 = Fun_ECM(y_hat2,y_test)\n",
    "print(\"Error cuadrático medio = \", ECM2)\n",
    "#Definición de Data Frame para el comparativo de los resultados\n",
    "MComp2 = pd.DataFrame(index=range(len(y_hat)),columns=[\"Datos verdaderos\",\"Datos aproximados\"])\n",
    "MComp2[\"Datos verdaderos\"] = y_test\n",
    "MComp2[\"Datos aproximados\"] = y_hat2\n",
    "MComp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
